# ğŸ§  NeuroInfuse ğŸ–¼ï¸

![ğŸ›ï¸ Bed demo](<./assets/bed demo.jpg>)

## ğŸ’¡ Inspiration
Non-creative individuals often struggle to visualize how different elements can come together cohesively. This limits their ability to explore design or architectural ideas. **NeuroInfuse** was created to solve this problem by leveraging AI to seamlessly integrate objects into background images while preserving their structure, making creative design accessible to everyone.

## âš™ï¸ What it does
**NeuroInfuse** is an AI-powered tool that seamlessly integrates objects into background images while maintaining their original structure. It functions like an automated version of Photoshop, using a **Stable Diffusion** model to blend elements naturally and realistically. Users can input objects and backgrounds, and the system generates a cohesive composition.

â–¶ï¸ ğŸ›ï¸ Watch Bed Demo

https://github.com/user-attachments/assets/102b4b08-79c1-47be-9976-39e98e67aff5

â–¶ï¸ ğŸ± Watch Cat Demo

https://github.com/user-attachments/assets/b1ac5dee-37c8-4300-927d-2409d92eb36e

## ğŸ”§ How we built it
NeuroInfuse was built using a combination of modern technologies:

- **ğŸ–¥ï¸ Frontend**: Developed with **React** and **TypeScript** for a responsive and intuitive user interface.
- **âš™ï¸ Backend**: Powered by **Python FastAPI** to handle communication between the frontend and the AI model.
- **ğŸ§  AI Model**: Utilized **PyTorch** and **Stable Diffusion** for image generation and integration.
- **ğŸ”— Integration**: The system was designed to ensure smooth interaction between the frontend, backend, and AI components.

Our backend is based on [ObjectStitch-Image-Composition](https://github.com/bcmi/ObjectStitch-Image-Composition) utilizing masked foreground images and employing all class and patch tokens from the foreground image as conditional embeddings.

![ğŸ› ï¸ System](<./assets/system.png>)

## ğŸš€ Get Started

### 1ï¸âƒ£ Dependencies

- **ğŸ Python** 3.9.21
- **ğŸ“¦ pip** 25.0.1

#### ğŸ–¥ï¸ Server Setup
```bash
pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 -f https://download.pytorch.org/whl/torch_stable.html
cd server
pip install -r requirements.txt
cd src/taming-transformers
pip install -e .
```

#### ğŸ—ï¸ Client Setup
```bash
cd client
npm install
```

### 2ï¸âƒ£ ğŸ“¥ Download Models

- Please download the following files to the `checkpoints` folder to create the following file tree:
  ```bash
  checkpoints/
  â”œâ”€â”€ ObjectStitch.pth
  â””â”€â”€ openai-clip-vit-large-patch14
      â”œâ”€â”€ config.json
      â”œâ”€â”€ merges.txt
      â”œâ”€â”€ preprocessor_config.json
      â”œâ”€â”€ pytorch_model.bin
      â”œâ”€â”€ tokenizer_config.json
      â”œâ”€â”€ tokenizer.json
      â””â”€â”€ vocab.json
  ```
- **ğŸ“¥ openai-clip-vit-large-patch14 ([Huggingface](https://huggingface.co/BCMIZB/Libcom_pretrained_models/blob/main/openai-clip-vit-large-patch14.zip) | [ModelScope](https://www.modelscope.cn/models/bcmizb/Libcom_pretrained_models/file/view/master/openai-clip-vit-large-patch14.zip))**.
- **ğŸ“¥ ObjectStitch.pth ([Huggingface](https://huggingface.co/BCMIZB/Libcom_pretrained_models/blob/main/ObjectStitch.pth) | [ModelScope](https://www.modelscope.cn/models/bcmizb/Libcom_pretrained_models/file/view/master/ObjectStitch.pth))**.

## â–¶ï¸ Run the App

#### ğŸ—ï¸ Client
```bash
npm run dev
```

#### âš™ï¸ Server
```bash
python .\scripts\main.py
```
